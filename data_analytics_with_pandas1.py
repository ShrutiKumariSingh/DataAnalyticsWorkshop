# -*- coding: utf-8 -*-
"""Data Analytics With Pandas1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TJp67fJpdsboKVO7-faQstv0i18dd6TC
"""

import pandas as pd
#lets verify it works by checking the version
print("Pandas is successfully imported version",pd.__version__)

#create an empty series
#import the pandas library and aliasing as pd
import pandas as pd
s=pd.Series()
print("Resulatant Empty Series: \n",s)

#creating a series from python list
#Step 1:Import pandas
import pandas as pd
#create a basic Python list of monthly active users (MAU s) for an app
mau_list=[1500,1800,2100,2500,3000]
#Create a pandas series from the list
monthly_series=pd.Series(mau_list)
#print the series
print("Monthly active users: \n ",monthly_series)

#creating series from numpy array with customize index
import numpy as np
import pandas as pd
#step 1: create a numpy array with daily sales numbers
daily_sales_array = np.array([100, 200, 300, 400, 500])
#step 2: create a series from the numpy array
daily_sales = pd.Series(daily_sales_array,index=  ["Mon", "Tue", "Wed", "Thu", "Fri"])
#step 3: print the series
print("Daily Sales Data: \n",daily_sales)

#create a dictionary representing country populations in  millions
pop_dict={'India':1400,'USA':332,'China':1441,'Brazil':214}
#creating series from dictionary
ps=pd.Series(pop_dict)
print("Population Data: \n",ps)

#creating series from scalar value
#Representing a single product price applied across 4 branches
p=pd.Series(999,index=['Miami','Los Angeles','Chicago','Denmark'])
print("Price of Product A across X branches \n",p)

#Accessing the series elements by position
import pandas as pd
#step 1:create a series with monthly data revenue
monthly_revenue=pd.Series([20,25,30,20,35],index=['jan','feb','mar','apr','may'])
print("January revenue: \n",monthly_revenue[0])
print("May revenue: \n",monthly_revenue[-1])

#Accessing by Label
import pandas as pd
#step 1:create a series with monthly data revenue
monthly_revenue=pd.Series([20,25,30,20,35],index=['jan','feb','mar','apr','may'])
#access value for march directly using label
print("Monthly revenye: \n",monthly_revenue['mar'])

#Slicing using positions
import pandas as pd
#step 1:create a showing number of passengers
p=pd.Series([120,125,130,124,135,140,180],index=['mon','tue','wed','thu','fri','sat','sun'])
#apply various slicing techniques
print("Slicing [1:0:2](tues to sat alternate days)\n",p[1:6:2])
print("Slicing [2:5](wed to fri)\n",p[2:5])
print("Slicing [3:(thurs to sun)\n",p[3:])
print("Slicing [:4](mon to thu)\n",p[:4])
print("Slicing [:](all days)\n",p[:])

#slicing a pandas series using index labels
import pandas as pd
#create a series of daily ticket sales(in thousands) over a week
ticket_sales=pd.Series([120,125,130,124,135,140,180],index=['2025-04-01','2025-04-02','2025-04-03','2025-04-04','2025-04-05','2025-04-06','2025-04-17'])
#slice sales from april 04 to april 17
selected=ticket_sales['2025-04-04':'2025-04-17']
print("Selected Sales: \n",selected)

#conditional access using boolean indexing
h=p[p>130]
print("Days with crowd \n",h)

#access using .get() to avoid errors
import pandas as pd
# create a series of average delay times(in  minutes )for flights over a week
print(p.get('wes',"Data not found"))

#example using all three attributes -dtype, shape and index of the series
print("Data type",ps.dtype)
print("Total records:",ps.shape)
print("Index Labels:",ps.index)

# Logical Operations on Series
#Monthly Cloud Costs
c=pd.Series([12000,13500,11000,14500,15000,12500],index=['jan','feb','mar','apr','may','jun'])
#find where cost exceeds 13000
h=c>13000
#outlier months where cost is either below 12k and 14.5k
outlier_months=(c<12000)|(c>14500)
#negate condition find months not exceeding 12k
w=~h
#use boolean mask to extract high cost values
f=c[h]
#use where() to keep values only above 13k others become nan
where_example=c.where(c>13000)
#use mask to hide costs below 13000
mask=c.mask(c<13000)
#use clip to restrict all values between 12k and 14k
clip_example=c.clip(lower=12000,upper=14500)
#print everything
print("Cost\n",c)
print("Months with cost>13k\n",h)
print("Outlier months\n",outlier_months)
print("Within Budget\n",w)
print("Filtered high costs:\n",f)
print("Using where\n",where_example)
print("Using mask\n",mask)
print("Using clip\n",clip_example)

#Mapping Department codes to names in a payroll system
#Department codes of employees
department_codes=pd.Series(['HR','ENG','MKT','HR','FIN','ENG'])
#Mapping to Full department names
dept_names={'HR':'Human Resource','ENG':'Engineering','MKT':'Marketing','FIN':'Finance'}
print("Before mapping:\n",department_codes)
#mapping with map
mapped=department_codes.map(dept_names)
print("Mapped:\n ",mapped)

#creating data frame from dictionary
import pandas as pd
import numpy as np
#create a dictionary of keys representing column names where each key has values which corresponds to their health
cd={'Patient ID:':['P101','P102','P103','P104','P105','P106','P107','P108','P109','P110'],
    'Age':[45,54,38,92,50,25,26,78,90,47],
    'Cholesterol_mg_dL':[190,205,170,180,160,110,150,190,187,168],
    'On-Statins':[True,False,True,False,True,False,False,True,True,False]
    }
df_medical=pd.DataFrame(cd)
print(df_medical)

#creating data frame from list
data=[1,2,3,4,5]
df=pd.DataFrame(data)
print(df)
#creating dataframe from numpy array
data=np.array([1,2,3,4,5,6,7,8,9,10])
df=pd.DataFrame(data)
print(df)

#Creating dataframe from CSV file
df_medical.to_csv('cd.csv',index=False)
df_loaded=pd.read_csv('cd.csv')
print(df_loaded)

#view first 5 rows of the dataframe

df_medical.info()
print("Describe the dataframe \n",df_medical.describe())
print("\n Detailed Description of the dataframe\n",df_medical.describe(include='all'))

#loc[] access rows and columns using label(names)
#get details of patients
da=df_medical.loc[:,['Patient ID:','Age']]
print(da)
statin=df_medical.loc[df_medical['On-Statins']==True]
print("Patients that are on statins:\n",statin)

#iloc Access rows and colums using positional indices
first_two=df_medical.iloc[0:2]
print(first_two)
age_cholesterol=df_medical.iloc[:,[1,2]]
print("Age and Cholesterol of all the patients:\n",age_cholesterol)

#at function
w=df_medical.at[1,'Patient ID:']
print(w)
#iat function
x=df_medical.iat[0,0]
print("Patient ID of first patient:\n",x)

#modify data frame data
df_medical['Age']=df_medical['Age']*12
print("DataFrame after converting age in years into months:\n",df_medical)

print("On-Statins\n",df_medical['On-Statins'])
df_medical.loc[df_medical['On-Statins']==True,'On-Statins']='1'
print("On-Statins\n",df_medical)

df = pd.DataFrame({
    'ShipmentID': [1001, 1002, 1003, 1004, 1005],
    'Weight_kg': [12.5, 8.0, 15.0, 7.5, 10.0],
    'Status': ['Delivered', 'In Transit', 'Delayed', 'Delivered', 'Delayed'],
    'Fragile': [True, False, True, False, True],
    'Shipping_Type': ['Air', 'Ground', 'Air', 'Ground', 'Air']
})

import pandas as pd
d= {
    "ShipmentID": [103, 101, 105, 102, 104],
    "OriginPort": ["Shanghai", "Rotterdam", "Singapore", "Dubai", "Los Angeles"],
    "DestinationPort": ["New York", "Hamburg", "London", "Tokyo", "Mumbai"],
    "Weight_Tons": [15.4, 25.1, 12.3, 18.7, 20.5],
    "DepartureDate": pd.to_datetime([
        "2024-09-01", "2024-08-25", "2024-09-10", "2024-08-28", "2024-09-03"
    ])
}
df=pd.DataFrame(d)
print(d)
sorted=df.sort_values(by='Weight_Tons',ascending=True)
print("Sorted by weight:\n",sorted)

#sort by original prt alphabetically and then by weight_tons
sort=df.sort_values(by=['OriginPort','Weight_Tons'],ascending=[True,False])
print("Sorted by origin and weight in tons:\n",sort)

#set shipment id as index and sort by index
s=df.set_index('ShipmentID')
sort=s.sort_index()
print("Sorted by index:\n",sort)

#sort the dataframe by weight tons using quick sort algo
sort=df.sort_values(by='Weight_Tons',kind='quicksort')
print("Sorted by weight using quick sort :\n",sort)

# Original DataFrame with vegetation zones
veg_df = pd.DataFrame({
    'Zone': ['Tundra', 'Taiga', 'Desert', 'Savanna', 'Rainforest'],
    'Continent': ['Arctic', 'Asia', 'Africa', 'Africa', 'South America'],
    'Avg_Temp_C': [-10, -5, 35, 28, 26]
})
print(veg_df)
veg_df=veg_df.set_index('Zone')
print("\n Original world vegetarian set: \n",veg_df)
#new desired order of vegetation zones
new=['Rainforest','Savanna','Steppe','Desert','Taiga','Tundra']
reindex=veg_df.reindex(new)
print("Reindexed set:\n",reindex)

#reindexing column
reindex_column=veg_df.reindex(columns=['Avg_Temp_C','Continent'])
print("Reindexed column:\n",reindex_column)

# fill missing values while reindexing
#reindexing and filling the missing values with defaults and printing
refill=veg_df.reindex(new,fill_value='Data NA')
print("Refill missing values:\n",refill)

#iteration
geo_df = pd.DataFrame({
    'Region': ['Amazon Basin', 'Sahara Desert', 'Himalayas', 'Great Plains'],
    'Elevation_m': [200, 450, 5200, 600],          # Elevation in meters
    'Rainfall_mm': [2200, 50, 1200, 900]           # Rainfall in millimeters
})
for index,row in geo_df.iterrows():
    print(f"Region:{row['Region']},Elevation:{row['Elevation_m']}m")

#Iterating with itertuples()
#using itertuples for faster row wise iteration
for row in geo_df.itertuples(index=False):
    print(f"{row.Region} receives about {row.Rainfall_mm}mm rainfall annually. ")

#Column wise iteration with items
for column_name,column_data in geo_df.items():
  print(f"\n Column :{column_name}")
  print(f"\n Column data{column_data.tolist()}")

# Northern climate data
north_df = pd.DataFrame({
    'Region': ['Arctic Circle', 'Northern Tundra'],
    'Avg_Temp_C': [-15, -10],
    'Biome': ['Tundra', 'Taiga']
})
print("Northern Climate Data\n", north_df)

# Southern climate data
south_df = pd.DataFrame({
    'Region': ['Amazon Basin', 'Patagonian Steppe'],
    'Avg_Temp_C': [27, 10],
    'Biome': ['Rainforest', 'Steppe']
})
print("\nSouthern Climate Data\n", south_df)
#rowwise concatenation of north_df and south_df
row = pd.concat([north_df, south_df], axis=0, ignore_index=True)
print("\nRow-wise Concatenation:\n", row)
#columwise concatenation
column = pd.concat([north_df, south_df], axis=1)
print("\nColumn-wise Concatenation:\n", column)
#concatenation with keys
keys = pd.concat([north_df, south_df], keys=['North', 'South'])
print("\nConcatenation with Keys:\n", keys)

#working with text data
data = {
    'Passenger': ['Alice', 'Bob', 'Carlos', 'Diana', 'Eva'],
    'Review': [
        'The flight was excellent and on time',
        'terrible service and rude crew',
        'food was okay but legroom was cramped',
        'Loved the inflight entertainment options!',
        'flight delayed by 3 hours, very annoying'
    ],
    'Airline': ['Delta', 'United', 'Lufthansa', 'Emirates', 'Qantas']
}
df=pd.DataFrame(data)
#text Cleaning and filtering
#convert all reviews to lowercase for normalisation
df['Review_lower']=df['Review'].str.lower()
#check if the word delayed is in the review
df['Contains_Delayed']=df['Review_lower'].str.contains('delayed')
#replace the world terrible with poor
df['Cleaned_Review']=df['Review_lower'].str.replace('terrible','poor',regex=False)
#count no of characters in the review
df['Review_length']=df['Review'].str.len()
#extract the first word using regex
df['First_Word']=df['Review'].str.extract(r'^(\w+)*')
#print the updated data frame
print(df)

data = {
    'ShipmentID': ['S001', 'S002', 'S003', 'S004', 'S005'],
    'PortOfOrigin': ['Shanghai', 'Hamburg', 'Singapore', 'Rotterdam', 'Mumbai'],
    'ShipmentStatus': ['In Transit', 'Delivered', 'Delayed', 'In Transit', 'Delivered']
}
df=pd.DataFrame(data)
#convert shipment status to categorical data
df['ShipmentStatus']=pd.Categorical(df['ShipmentStatus'])
print(df)
print("Data types:\n",df.dtypes)

#sorting ordering and comparison
status_order=['Delayed','In Transit','Delivered']
df['ShipmentStatus']=pd.Categorical(df['ShipmentStatus'],categories=status_order,ordered=True)
sorted_df=df.sort_values('ShipmentStatus')
print("Sorted by shipment status:\n",sorted_df)

#Memory Optimization with categoricals
import numpy as np
data = {
    'PatientID': ['P001', 'P002', 'P003', 'P004', 'P005'],
    'Temperature_C': [36.6, np.nan, 38.1, 37.5, np.nan],
    'Blood_Pressure': ['120/80', '130/85', np.nan, '110/70', '125/82'],
    'Heart_Rate': [72, 85, 88, np.nan, np.nan],
    'Respiratory_Rate': [18, np.nan, 20, 19, 21]
}
df=pd.DataFrame(data)
print(df)

#detecting missing values
missingvalues=df.isna()
missing=df.isna().sum()
print("Mising matrix:",missingvalues)
print("Missing counts:\n",missing)

df['Temperature_C']=df['Temperature_C'].fillna(df['Temperature_C'].mean())
df['Heart_Rate']=df['Heart_Rate'].fillna(75)
print("\n After filling rows with all vitals missing:\n",df)
df_dropped=df.dropna(how='all', subset=['Temperature_C','Blood_Pressure','Heart_Rate','Respiratory_Rate'])
print("\n After dropping rows with all vitals missing:\n",df_dropped)

data = {
    'Container_ID': ['C001', 'C002', 'C003', 'C001', 'C004', 'C002'],
    'Origin_Port': ['Shanghai', 'Rotterdam', 'Dubai', 'Shanghai', 'Singapore', 'Rotterdam'],
    'Destination_Port': ['Los Angeles', 'New York', 'Hamburg', 'Los Angeles', 'Tokyo', 'New York'],
    'Weight_Tons': [20, 25, 18, 20, 30, 25]
}
df=pd.DataFrame(data)
print(df.duplicated())
df_dedup=df.drop_duplicates()
print(df_dedup)
df_unique_characters=df.drop_duplicates(subset=['Container_ID'])
print(df_unique_characters)

data = {
    'Container_ID': ['C001', 'C002', 'C003', 'C001', 'C004', 'C002'],
    'Origin_Port': ['Shanghai', 'Rotterdam', 'Dubai', 'Shanghai', 'Singapore', 'Rotterdam'],
    'Destination_Port': ['Los Angeles', 'New York', 'Hamburg', 'Los Angeles', 'Tokyo', 'New York'],
    'Weight_Tons': [20, 25, 18, 20, 30, 25]
}
df=pd.DataFrame(data)
uniq=df['Destination_Port'].unique()
print("Unique Destination Port:\n",uniq)
#unique container ids
uniq_id=df['Container_ID'].unique()
print("Unique Container IDs:\n",uniq_id)
#print frequency of each origin port
port_freq=df['Origin_Port'].value_counts()
print("Frequency of Origin Ports:\n",port_freq)

#Dataframe w dupes col labels
df_dupes = pd.DataFrame([[1,2,3], [4,5,6]], columns=['A', 'B', 'A'])
print("Duplicated col:\n", df_dupes.columns.duplicated())

# craete sample datframe w dupes row indices
df_dupes = pd.DataFrame({'Shipment': ['Box1', 'Box2', 'Box3'],
                         'Weight': [10, 20, 30]}, index=[0, 1, 1])
print("Duplicated index:\n", df_dupes.index.duplicated())

ota_data = pd.DataFrame({
    'PassengerID': [101, 102, 103],
    'Origin': ['JFK', 'LHR', 'DXB'],
    'Destination': ['CDG', 'DEL', 'HND'],
    'FareUSD': [520, 690, 830]
})

# Create Airline website bookings DataFrame
airline_data = pd.DataFrame({
    'PassengerID': [104, 105],
    'Origin': ['SIN', 'SFO'],
    'Destination': ['SYD', 'ICN'],
    'FareUSD': [720, 640]
})

# Combine both datasets vertically (row-wise)
combined_data = pd.concat([ota_data, airline_data], ignore_index=True)

print(combined_data)

tickets = pd.DataFrame({
    'PassengerID': [101, 102, 103],
    'Origin': ['JFK', 'LHR', 'DXB'],
    'Destination': ['CDG', 'DEL', 'HND']
})

# Airport metadata
airports = pd.DataFrame({
    'AirportCode': ['JFK', 'LHR', 'DXB', 'CDG', 'DEL', 'HND'],
    'Country': ['USA', 'UK', 'UAE', 'France', 'India', 'Japan']
})
merge=tickets.merge(airports,how='left',left_on='Origin',right_on='AirportCode')
print(merged)

schedule_df = pd.DataFrame({
    'FlightNo': ['AI101', 'BA204', 'LH789', 'EK501'],
    'Origin': ['Delhi', 'London', 'Frankfurt', 'Dubai'],
    'Destination': ['New York', 'Mumbai', 'Tokyo', 'Singapore']
}).set_index('FlightNo')

# Prices DataFrame: ticket prices
prices_df = pd.DataFrame({
    'FlightNo': ['AI101', 'BA204', 'SQ802', 'EK501'],
    'FareUSD': [850, 920, 780, 730]
}).set_index('FlightNo')
left_join=schedule_df.join(prices_df,how='left')
print(left_join)
right_join=schedule_df.join(prices_df,how='right')
print(right_join)
inner_join=schedule_df.join(prices_df,how='inner')
print(inner_join)
outer_join=schedule_df.join(prices_df,how='outer')
print(outer_join)

fare_data = pd.DataFrame({
    'Route': ['NYC-LON', 'NYC-LON', 'NYC-LON', 'DEL-TYO', 'DEL-TYO', 'DEL-TYO'],
    'Class': ['Economy', 'Business', 'First', 'Economy', 'Business', 'First'],
    'FareUSD': [500, 1200, 2200, 450, 1100, 2100]
})
print("All Data \n",fare_data)
#Printing Pivoted data one row per route one column per class
pivoted_fares=fare_data.pivot(index='Route',columns='Class',values='FareUSD')
print("Pivoted Data \n",pivoted_fares)

#pivot table-Average fair by origin and price
fare_data = pd.DataFrame({
    'Route': ['NYC-LON', 'NYC-LON', 'NYC-LON', 'DEL-TYO', 'DEL-TYO', 'DEL-TYO'],
    'Class': ['Economy', 'Business', 'First', 'Economy', 'Business', 'First'],
    'FareUSD': [500, 1200, 2200, 450, 1100, 2100]
})
pivot_table=fare_data.pivot_table(values='FareUSD',index='Route',columns='Class',aggfunc='mean')
print("Pivot Table\n",pivot_table)